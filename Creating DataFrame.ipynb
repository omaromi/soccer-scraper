{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# A function that translates the json_string into a unicode string\n",
    "def jsonreader(exstring):\n",
    "    ind_s = exstring.index(\"('\")+2\n",
    "    ind_e = exstring.index(\"')\")\n",
    "    json_data = exstring[ind_s:ind_e]\n",
    "    return json.loads(json_data.encode('utf8').decode('unicode_escape'))\n",
    "\n",
    "#I found that the first game of the season was Brentford 2 - 0 Arsenal, looked for that url. Then \n",
    "# tested higher number urls until i got to a recent game i recognized.\n",
    "base_url = 'https://understat.com/match/'\n",
    "matchnum = list(range(16376,16607)) \n",
    "#matches 16376->16607\n",
    "\n",
    "urls = []\n",
    "\n",
    "#After loading all the urls of premier league games, I wanted to find strictly the Arsenal game urls. \n",
    "# Filtering down early saves time later on. This is fine since I only want Arsenal data.\n",
    "for each in matchnum:\n",
    "    url = base_url+str(each)+'/'\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content, 'html.parser')\n",
    "    header = str(soup.find('title'))\n",
    "    if header.find('Arsenal') != -1:\n",
    "        urls.append(url)\n",
    "        \n",
    "\n",
    "print(urls)\n",
    "\n",
    "#I'm defining this early. This will become the dataset that eventually becomes the dataframe for use in pandas.\n",
    "seasonrosterdata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54042515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to find my columns. The best way to do that is work with a specific json_string and find the columns info in there.\n",
    "r1 = requests.get('https://understat.com/match/16376')\n",
    "\n",
    "soup1 = bs(r1.content, 'html.parser')\n",
    "\n",
    "scripts1 = soup1.find_all('script')\n",
    "\n",
    "rosters_json_string1 = ''\n",
    "for each in scripts1:\n",
    "    if 'rostersData' in each.text:\n",
    "        rosters_json_string = each.text.strip()\n",
    "\n",
    "json_dict1 = jsonreader(rosters_json_string)\n",
    "\n",
    "# column and values names for an individual player\n",
    "firstplayer = json_dict1['a']['475189']\n",
    "columns = list(firstplayer.keys())\n",
    "print(columns)\n",
    "#I need the team_id for Arsenal\n",
    "print(firstplayer['player'])\n",
    "print(firstplayer['team_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54430f72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content, 'html.parser')\n",
    "    scripts = soup.find_all('script')\n",
    "\n",
    "    rosters_json_string = ''\n",
    "    for each in scripts:\n",
    "        if 'rostersData' in each.text:\n",
    "            rosters_json_string = each.text.strip()\n",
    "    json_dict = jsonreader(rosters_json_string)\n",
    "    \n",
    "    for row in json_dict['h']:\n",
    "        seasonrosterdata.append(list(json_dict['h'][row].values()))\n",
    "\n",
    "    for row in json_dict['a']:\n",
    "        seasonrosterdata.append(list(json_dict['a'][row].values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(seasonrosterdata,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24126751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs('/Users/fsa168/Desktop/PythonPractice/SoccerScraper', exist_ok=True)\n",
    "\n",
    "# df.to_csv('/Users/fsa168/Desktop/PythonPractice/SoccerScraper/full_season_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n",
    "# filt = (df['team_id'] == 83)\n",
    "\n",
    "# Arsdf = df.loc[filt, 'player']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eabdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
